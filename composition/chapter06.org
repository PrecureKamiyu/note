#+title: Memory Heirarchy from the RISCV BOOK
* Chapter six: Memory Heirarchy

The chapter is about /Memory Heirarchy/. You should already know a
little about it if you have read /CSAPP/.

Note that the note is based on the side notes. You need to check both side notes and books. 

** Intro 
*** Principle of Locality
- /principle of locality/ 
  - /temporal locality/: like frequently-accessed data
  - /spatial locality/: like an array

- /memory heirarchy/: something like a pyramid.

-----------------

- /Blocks/: Cache memory is organized into a series of blocks, also known as lines 1. Each block contains a certain amount of data and has its own block address 1. The size of the block and the overall capacity of the cache are two important factors that affect the performance of the cache memory 1. The spatial aspect suggests that instead of fetching just one item from the main memory to the cache, it is useful to fetch several items that reside at adjacent addresses as well 2.
- /hit/, /hit rate/: if the block is the block that we want, then we hit. We could also miss, that is, not to hit. If we miss, we have to access lower level to find the block that we want, and send it to the cache. Hit rate is *the fraction of memory accesses found in the upper level*.  Hit rate is the measure of the performance of the cache.
- /hit time/, /miss penalty/: Hit time is the time we need to access data when hit. When we miss, we have to retrieve data from lower level. The extra time we spend is the miss penalty. 

#+BEGIN_NOTE
miss penalty The time required to fetch a block into a level of
the memory hierarchy from the lower level, including the time to
access the block, transmit it from one level to the other, insert it
in the level that experienced the miss, and then pass the block to the
requestor.
#+END_NOTE

----------

Here is a self check: 

Which of the following statements are generally true?
1. Memory hierarchies take advantage of temporal locality.
2. On a read, the value returned depends on which blocks are in the cache.
3. Most of the cost of the memory hierarchy is at the highest level.
4. Most of the capacity of the memory hierarchy is at the lowest level.

And here is the answer:
1. True. Memory hierarchies take advantage of temporal locality by keeping recently accessed data in the faster, higher levels of the hierarchy so that future accesses to that data can be faster.
2. True. On a read, the value returned depends on whether the requested data is present in the cache or not. If it is present, the value is returned quickly from the cache. If it is not present, the value must be fetched from a lower level of the memory hierarchy, which takes longer.
3. False. Most of the cost of the memory hierarchy is at the lowest level (usually secondary storage), which is typically much larger and more expensive than the higher levels (such as cache and main memory).
4. True. Most of the capacity of the memory hierarchy is at the lowest level (usually secondary storage), which is typically much larger than the higher levels (such as cache and main memory).

#+begin_center
here is a centered text.
#+end_center

** Memory Technologies

- /DRAM/ and /SRAM/: /D/ stands for *dynamic*, which is to say that the value it stored have to be refreshed every once a while or it will fade away. /S/ stands for *static*, saying that the value will not fade away.
- /Flash Memory/: widely used in cell phone.
- /Magnetic Disk/: with a big capacity.

---------------

The difference of /DRAM/ and /SRAM/: Answered by *Google Bard*

Static RAM (SRAM) is a type of random access memory (RAM) that stores data in flip-flops. Flip-flops are electronic circuits that can store a single bit of data, either a 0 or a 1. As long as power is applied to the SRAM, the data stored in the flip-flops will be maintained indefinitely.

Dynamic RAM (DRAM) is a type of random access memory (RAM) that stores data in capacitors. Capacitors are electronic components that can store an electric charge. The amount of charge stored in a capacitor can be used to represent a 0 or a 1. However, the charge in a capacitor will slowly leak away over time. Therefore, DRAM must be refreshed periodically to prevent the data from being lost.
The main difference between SRAM and DRAM is that SRAM stores data in flip-flops, while DRAM stores data in capacitors. This difference in storage mechanism has several implications:

- Basic Unit: SRAM use /flip-flops/ and DRAM use /capacitors/. A filp-flop consists of six transistors maybe, and a capacitor is made of one or two transistors.
- Speed: SRAM is faster than DRAM because it does not need to be refreshed periodically.
- Cost: SRAM is more expensive than DRAM because it requires more transistors per bit of storage.
- Density: DRAM is denser than SRAM because it can store more data in the same amount of space.
- Refresh rate: SRAM does not need refreshing, while that DRAM need refreshing.

-------

- /two-level coding structure/

In the context of DRAM (Dynamic Random Access Memory), a row refers to a set of memory cells that share a common word line. A word line is an electrical line that selects a row of cells in the memory array. When a row is selected, all the cells in that row can be accessed simultaneously.

In your example, if a word is 32 bits long and there are 1024 words, then there would be 1024 rows and each row would have 32 bits. Each bit in a row would correspond to one memory cell.