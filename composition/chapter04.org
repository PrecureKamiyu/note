* 第四章 前篇---cpu 的组成
** 概述
*** cpu 的构造法
对于一个 cpu , 其中分为三个部分. 第一个部分是处理器, 第二部分是内存,
第三部分是总线.  
1. 处理器, 里面由 ALU, 寄存器, PC
2. 内存, 就是内存相关的, Cache 缓存, memory 内存.
3. 总线, 就是 IO 相关的
*** PC
PC 就是存储着指令, 其告诉 ALU 该如何处理寄存器. 
*** ALU
ALU 就是运算单元, 其能够执行 add sub 等指令, 对寄存器进行操作. 
*** CACHE
**** Cache 简介
Cache 是缓存, 是一种更为快速的内存. 速度和数量介于内存和寄存器之间. 

Cache 用于提高效率. 我们目前知道了三种不同效率的存储单元, 将适合的任务
分配给它们, 以此提高效率 (当然也是成本效率)
**** SRAM

Cache memory operates between 10 to 100 times faster than RAM,
requiring only a few nanoseconds to respond to a CPU request. The name
of the actual hardware that is used for cache memory is high-speed
static random access memory (SRAM).

实现的 Cache 的硬件为 SRAM, (high-speed static random access
memory). 而 DRAM (dynamic random access memory) 用于构建 memory.SRAM
之中的数据, 只要没有断电 (power), 就能够一直保存, 不同于 DRAM 的数据那
样, DRAM 之中的数据, 一把来说几秒钟后就会消失, 需要周期性地 refresh 一
下. SRAM use latches and transistor to store data.  
**** Cache 的多级建构

Cache 分为了三个 Level, 有 L1, L2, L3, 其中 L3 速度最慢, 是用来辅助
L1, L2 的.

Cache memory is a small amount of fast memory that is used to store
frequently accessed data. It is located close to the CPU and is used
to reduce the average time it takes to access data from the main
memory. 

There are three general levels of cache: L1 cache, L2 cache, and L3
cache. Each level is differentiated by its speed, size, and proximity
to the CPU. 

L1 cache, or primary cache, is extremely fast but relatively small. It
is usually embedded in the processor chip as CPU cache³. 

L2 cache, or secondary cache, is often more capacious than L1 but
slower. It is usually located on the processor chip or on a separate
chip on the motherboard³. 

L3 cache, or tertiary cache, is larger than L2 but slower. It is
usually located on a separate chip on the motherboard³. 

Is there anything else you would like to know about cache memory?

Computers, Explained -SearchStorage. https://www.techtarget.com/searchstorage/definition/cache-memory
访问时间 2023/4/1.

(2) Explainer: L1 vs. L2 vs. L3 Cache |
TechSpot. https://www.techspot.com/article/2066-cpu-l1-l2-l3-cache/ 访
问时间 2023/4/1.

(3) How Does CPU Cache Work and What Are L1, L2, and L3 Cache? -
MUO. https://www.makeuseof.com/tag/what-is-cpu-cache/ 访问时间
2023/4/1.                                               
** interlude

Havard architecture and Princeton architecture

程序有存储的地方, 数据也有存储的地方, 我们常将其抽象出来, 认为这两个部
分是存在一个地方里的. 但实际上有区别. 

数据的存储单元, 程序的存储单元, 在哈佛架构之中是分开的. 也就是说, 在哈
佛架构中, 存在两个单元, 分别由两个总线进行单元和处理器之间的数据传输
** 组件的硬件构成
*** Processor 的简单构成  
**** ALU Register PC Extender

1. ALU 是算术运算单元, 即, 进行 and or add sub 运算的单元.
2. Register 我们很熟了, 支持读写操作. PC 我们也很熟了, 支持 +4 , + imm
   操作.
3. Extender 是 imm 生成单元也是扩展单元,我们有的时候需要进行一些数据的
   符号扩展.  
**** ALU (算术逻辑运算单元) 的功能和硬件实现 [100%]

- [X] 完善该标题
输入两个 32 位数据, 输出一个 32 位的数据. 进行位运算或者加减运算. 

***** ALU 的接线

一个一位 ALU 单元应该
1. 根据 ALU control 的值, 决定 ALU 该执行什么运算
2. 根据输入 A B 给出结果 R
3. 判断是否溢出, 接出一根线: Overflow, 其值为 1 当且仅当发生溢出
4. 判断结果是否为 0, 接出线: Zero, 其值为 1 当且仅当结果为 0
5. 接出一根线, Carry Out. 用于串联的进位
***** AlUop 和 ALU control 

ALUop 是一个二位的信号, 其和 funct field 结合在一起, 通过 ALU 
control 单元, 生成一个 ALU control 信号. 

这里使用的是多级[fn:1]的控制信号生成器. 多级, 但是每一级的规模很小, 这
使得信号生成的延迟降低了. 控制信号的延迟是非常重要的参数. CPU 的时钟周
期就取决于这个参数.

但是出于不明原因, 我们这里居然没有提及 ALU control 信号, 将其和 ALUop
混为一谈, 着实离谱. 下面有一些 ALUop 的出现, 他们实际上指的是 ALU
control 信号

[fn:1] 这种多级译码的方式---主控制单元生成 ALUop 位作用 ALU 的输入控制
信号, 在生成实际信号来控制 ALU---是一种常见的方式. 多级控制可以减小主
控制单元的规模. 多个小的控制单元可以潜在地减小控制单元的延迟. 


ALUop 是指令码的一个字段, 其和 funct 字段经过 ALU 控制单元生成实际的控
制信号. 见下表:

|-------+---------+--------+------|
| ALUop |  funct7 | funct3 | 操作 |
|    00 | XXXXXXX |    XXX | 0010 |
|    X1 | XXXXXXX |    XXX | 0110 |
|    1X | 0000000 |    000 | 0010 |
|    1X | 0100000 |    000 | 0110 |
|    1X | 0000000 |    111 | 0000 |
|    1X | 0000000 |    110 | 0001 |
|-------+---------+--------+------|


能够看出, 实际上控制单元的输入可以简化, 比如说
***** ALU control 信号的功能

| ALU con | 操作 |                  |
|    0000 | and  |                  |
|    0001 | or   |                  |
|    0010 | add  |                  |
|    0110 | sub  | substraction     |
|    0111 | slt  | set on less than |
|    1100 | nor  |                  |

注意 ALU con 的后两位是用于 Multiplexer 的. 
**** ALU 的硬件实现
***** 构建简单的 ALU

以 Multiplexer 为基础, 而后构建 and or add 操作
and 使用 and 门, or 使用 or 门, add 使用一个一位 Full adder. 
构建是简单的.

ALU con 的后两位是用于 Multiplexer 的
- 00 代表 Multiplexer 的第 0 个输入: A and B
- 01 代表 Multiplexer 的第 1 个输入: A or  B
- 10 代表 Multiplexer 的第 2 个输入: A + (B)
- 11 代表 Multiplexer 的第 3 个输入: Less

其中 (B) 代表对 B 进行一定处理之后的数据. Less 是 slt 的实现之中会稍微
提及的一个信号. 

***** one bit ALUs 的串联 [5/5]

在串联之中我们要实现
- [X] sub 操作
- [X] slt 操作
- [X] nor 操作 
- [X] Overflow 判断
- [X] Zero 判断

****** sub 操作

设 ALUop 的第三位为 Binvert. 通过等式 R = A - B = A + B'来实现减法.

1. 在 one bit ALU 之中, 通过一个 Mux 和反相器, 使 B 取反
2. 接入末位 ALU viz., ALU0 的 CarryIn. 使得结果 +1

这就有 R = A+B'+1. 也就有 R = A-B. 

****** slt 操作

我们接入 Less 信号, 作为 ALU 的输入, 这是当然的. Less 信号很特殊, 他在
one bit ALU 之中直接输出, 并且整体作为 Mux 的最后一个输入. 因为 slt 的
结果 R 比较特殊, 只有两个取值: 1 和 0; 即, 说除了末位, 所有位的值
为 0. Less 也是如此. 而对于末位, 只需要将 A - B 的结果的符号位塞进去就
行了. 设结果为 R 

R = (A < B) 

true 代表 1, false 代表 0. 我们用 Less 作为 one bit ALU 的输入信号. 
我们只需要计算出 A - B 的值, 然后 A - B 的符号传回 Less 的末位 (Less
在其他位的值均为0), 最后 result 直接等于 Less.  

****** nor 操作 

ALUop = 1100 的时候, 其为 ALU 为 nor 操作. 观察后两位, 这个时候
Multiplexer 选择第 0 位数据理论上进行的是 and 操作, 只需要让 ALUop 的
最高位为 Ainvert. 其为 1 的时候, A 的数据反相. 由于

$$
\overline {A + B} = \overline A * \overline B
$$

就有 $R = \overline{A + B}$

****** Overflow 判断

设我们从0开始计数. 设 CarryOut 为进位. 能够验证, 若是 Overflow 为 1 的
时候, 发生溢出, 有:

    Overflow = CarryOut[30] xor CarryOut[31]

CarryOut[30] 为最高非符号位的进位, CarryOut[31] 为符号位的进位. 比如说,
我们有两个正数相加, 两个符号位为 0, 那么 CarryOut[31] 为 0; 而后, 溢出
的时候, 相当于, CarryOut[30] 为 1 (不然的话, 两个正数都小于2^{29}) ;
同理, 对于两个负数相加的时候, 符号位进位为 1, 最高非符号位进位为 0. 

总之你意会一下. 
****** Zero 判断

每一位结果取 nor 即为结果. Mux 的输出 Result 信号每一位取 nor.

**** PC

PC 是一个寄存器, 存储着 ~当前指令~ 的地址 [fn:2]. 当当前指令执行完毕之
后,  PC = PC + 4, 其值指向下一条指令.   

并且, 在 SB 型指令, viz., 分支跳转的指令 (比如说 bne) 执行的过程之中, 
PC 还有可能变为 PC + offset. 

那么 PC 应

   1. PC 能够变为 PC + 4
   2. PC 能够变为 PC + offset, 其中 offset 是来自立即数产生器的. 

那么 PC 应该有一个控制信号, 来表明是情况1. 还是情况2. 一般来说, 我们将
这个信号称为 PCsrc. 他表明着 PC 的输入来源. 

[fn:2] 根据 PC 的值取出指令之后, 一般来说, PC 的值就更新了. 在很多地方
说 PC 存储的是下一条指令的地址, 其实无论怎么说都好象不是很靠谱. 因为我
们应当将 PC 值更新的时刻点明出来. 

**** Register (寄存器)

我们应该有这些功能:
1. 根据 Register 编号 Rw 将 busW 写入到寄存器之中
2. 根据 Register 编号 Ra Rb 将寄存器的值输出到 busA, busB 上

并且读操作不应收到时钟控制. 其也有控制信号: RegWrite 信号, 表明其是否
要写入. src 有两种可能, 其有可能是来自于内存, 也有可能来自于 ALU. 前者
对应的便是 L 型指令, 后者对应的指令有 I 型指令等. 这种条件的选择也由一
个控制信号来控制, 称为 MemtoReg 

*** Memory 的简单构成
**** 数据存储器

应当采用时序逻辑设计. 
其应做到, 将指定的数据 DataIn 写入到 Addr 指定的内存位置里, 并且能够根
据指定的 Addr 将内存中对应的数据写到输出 DataOut 上. 这就是读写操作,
但其中读的操作不应该受到时钟的控制 (至少是可以不受到时钟的控制) 

**** 指令存储器

一个程序运行的之前, 程序装载器将程序装载起来, 在程序运行过程中, 不能对
指令存储器进行写入的操作. 

其应做到
1. 根据对应的 Addr 给出对应位置存储的指令. 
2. 不能在程序运行过程对其进行写操作. 

*** Control 单元简单介绍
**** ALU control 单元

说实话我们以及介绍过了. 这里就不介绍了.

**** Control 单元

虽然我们还没怎么说, 但是上文已经提到了非常多的控制信号. 这些控制信号,
比如说 MemtoReg, 比如说 ALUop (ALUop 是作为 ALU control 的控制信号),
这些控制信号, 实际上是直接由指令码的 opcode field 而来, viz., control
单元的输入信号为 instruction[6:0], viz., opcode. 

我们先来数一下有多少个输出信号

    1. Branch 用于分支
    2. MemRead 如其名
    3. MemtoReg 确定 Reg 的来源
    4. ALUop 两位信号, 生成 ALU 的控制信号
    5. MemWrite 如其名
    6. ALUSrc 确定 ALU 的 source 因为其可以是立即数也可以是寄存器的值.
    7. RegRead 如其名

是的, 还真就几把那么多[fn:2]. 那么我们可以将 Control 单元看作是一个译
码器:
    I: instruction[6:0]
    O: 上面 8 位数据. 


[fn:2] PCSrc 是一个衍生信号, 并不是 Control 的直接输出.

** 在简单指令运行之前

在下一个部分开始之前, 我们细说一下各个模块之间的联系. 我们从左到右开始
*** PC

最左边是 PC, PC 有两种情况, PC = PC + 4 以及 PC = PC + offset. 这里的
两种加法不通过 ALU, 而是由两个加法器构成. 其中一个加法器为

PC + 4 

另一个加法器为 

PC + offset

其中 offset 是 imm, 那么就是来自于立即数生成器---imm-Gen 
*** IM

随后是 instruction memory. 输入---PC, 输出---32位的指令---instruction. 

*** Reg 


我们应该有这些功能:
1. 根据 Register 编号 Rw 将 busW 写入到寄存器之中
2. 根据 Register 编号 Ra Rb 将寄存器的值输出到 busA, busB 上

并且读操作不应收到时钟控制. 其也有控制信号: RegWrite 信号, 表明其是否
要写入. src 有两种可能, 其有可能是来自于内存, 也有可能来自于 ALU. 前者
对应的便是 L 型指令, 后者对应的指令有 I 型指令等. 这种条件的选择也由一
个控制信号来控制, 称为 MemtoReg 
End of quote

能够看出 Ra, Rb, Rw 都是来源于 instruction 的. Register 有可能接
收 1. ALU 的值 2. 内存的值. 

*** ALU 

其源可能是 Reg 也可能是 imm. 

PCsrc = Zero and Branch 

对于 bne 指令, 寄存器 A 等于 寄存器 B 的时候 (也就是 A - B = 0) 的时候
进行跳转, 跳转就意味着 PC = PC + offset. 

*** Memory 

其输出可能用于 load 指令, load 指令将内存里面的东西放到寄存器里面. 

大概就这些, 一些无伤大雅的复读. 
** 简单指令的运行

以 add rd, rst1, rst2 为例:

1. PC 取指令, PC + 4
2. ins 的值输入到寄存器组件, rst1 rst2 输入到 ALU 之中
3. ALUop 和 funct 经过 ALU control 中心, 输入给 ALU, 确定 ALU 进行的运
   算类型. ALU 得到的值, 输入到寄存器组件之中
4. 寄存器将这个值写到 rd 上.

我们不妨验证一下, Control 的值都是些什么

|--------+----------+----------+---------+----------+--------+-------|
| ALUSrc | MemtoReg | Regwrite | MemRead | MemWrite | Branch | ALUop |
|      0 |        0 |        1 |       0 |        0 |      0 |    10 |
|--------+----------+----------+---------+----------+--------+-------|

ALU 的 sauce 为 rst2; 不设计内存操作; 结果写入 rd; 不是分支判断

|--------+------+-----+--------+----+--------|
| funct7 | rst2 | rs1 | funct3 | rd | opcode |
|      7 |    5 |   5 |      3 |  5 |      7 |
|--------+------+-----+--------+----+--------|

----------------------------------------------------------------------

以 ld rd offset(rst1) 为例:

   1. PC 取指令, PC + 4
   2. 寄存器输出 rst1, imm-Gen 输出 offset, 送入到 ALU 之中
   3. ALU 将运算结果送到内存之中, 内存输出对应的值
   4. 内存输出的值送到寄存器单元, 写到 rd 上面. 

我们进行验证: 
   - ALUsrc   为 1, 因为操作数有 imm
   - MemtoReg 为 1, 因为寄存器将内存的值写到了 rd 上
   - Regwrite 为 1, 因为 rd 被写入了
   - MemRead  为 1, 因为内存要读数据
   - MemWrite 为 0, 因为不用写入内存
   - branch   为 0, 这是肯定的

----------------------------------------------------------------------

以 beq rst1, rst2, offset 为例:

   1. PC 取指令 
   2. 取出 rst1, rst2 的值
   3. 取出 offset 的值, 符号扩展, 左移一位, 和 PC 的值进行相加; ALU 进
      行 rst1 - rst2 的运算, 输出 Zero
   4. 根据 branch 和 zero 的值决定 PC 的值. 

可以看见 branch 用上了, 对于控制信号的验证我就不说了. 
** 更多的指令

对于 I 型指令的 jalr 
     J 型指令的 jar 等
     U 型指令的 auipc 等, 
     B 型指令(SB型指令)的 blt, bne 等指令
我们目前没能实现. 比如说 jalr 会将 PC 之中的值存入寄存器中, 我们还没有
     实现这点, auipc 也是同理. blt 则是控制信号还不够, 目前只能有 beq
     的实现. 

实际上这些细节能够自己补全. 我大概想出了两种方法: 1. 接一条线到ALU上;
2.PC + offset 的加法器接出一条线, 接到寄存器上面. 稍微考虑一下,两种方
法都有问题: 1. 接到 ALU 上, 那么我们在 beq 或者是 bne 之中就用不上 ALU
的 Zero 值了, 然后 PC +offset 的部分都稍微重构一下; 2. 如果说 PC +
offset再接到寄存器单元上, 那么寄存器的输入就有三种情况了, imm, 内存数
据, pc值. 那么说要多一个控制信号... 其实也不是不能接受. 


对于 SB 型指令的 blt, 还有更为糟糕的, bltu, 我们需要进行无符号的比较.
说实话不太清楚该怎么作. 在 ppt 上, 处理方法是引入一个比较单元, 分支跳
转模式的 bne beq blt bge bltu 等指令中, 将寄存器数输入到比较单元, 直接
输出结果. 有点粗暴, 并且没有用到 ALU 的 Zero 值. 

到时候应该是要自己实现这个 cpu 的, 说实话我觉得还行. 

* 第四章 后篇---流水线
** 流水线 1
*** 引入 Why 流水线

我们前面列出了一个指令的运行流程, 这个运行过程可能要经过多个时钟周期,
完成4到5个操作. 为什么不使用单个周期呢, 也就是执行完了一个指令之后, 
再进行下一个指令的执行?

在CPU的设计之初, 研发人员也是这么想的, 设计出来的CPU也是如此. 可是到了
至之后, 引入了浮点相关的运算之后, 其设计的CPU甚至无法正常运行了. 这是
因为一个指令的执行时间有长有短,周期的长度由实行时间最长的那个指令决定.
那些执行时间短, 使用频率高的指令的执行效率却变低了.于是我们就违反了原
则---加速经常性时间.

并且, 我们考虑 CPU 的内部, 比如说, 当我们取PC值的时候, 这个时钟周期里
面, CPU的其他部分都是没有工作的, 造成浪费. 应尽量利用其这部分, 让其多
干些活, 提高效率. 所以就要引入流水线. 虽然说, 对于单个指令---或者是用
洗袜子的比喻来说---对于一双袜子来说, 洗所需要的时间没有发生变化[fn:3]
但流水线提高了整个系统的吞吐量, 在洗多双袜子的时候效率就会提高.

[fn:3] 甚至为了流水线的正常运行做出了一定的让步. 


一个指令的执行过程通常包括了五个部分: 
  1. 从存储器读出指令
  2. 读寄存器并且译码指令
  3. ALU 进行运算
  4. 访问内存
  5. 将结果写回寄存器


假设我们不适用流水线, 我们结果将会是这个样子
|-------+-----+----+-----+-----+----+----+----+-----+-----+----+-----|
| 时间  |           800ps           |    |    |     |     |    |     |
|-------+-----+----+-----+-----+----+----+----+-----+-----+----+-----|
| 指令1 |  IF | ID | ALU | Mem | WB |    |    |     |     |    |     |
|-------+-----+----+-----+-----+----+----+----+-----+-----+----+-----|
| 指令2 |     |    |     |     |    | IF | ID | ALU | Mem | WB |     |
|-------+-----+----+-----+-----+----+----+----+-----+-----+----+-----|
| 指令3 |     |    |     |     |    |    |    |     |     |    | ... |
|-------+-----+----+-----+-----+----+----+----+-----+-----+----+-----|
                                   
但是使用了流水线, 
|-------+----+----+-----+-----+--------+-----+----|
| 时间  |           1000ps             |     |    |
|-------+----+----+-----+-----+--------+-----+----|
| 指令1 | If | Id | Alu | Mem | WB     |     |    |
|-------+----+----+-----+-----+--------+-----+----|
| 指令2 |    | IF | ID  | ALU | Mem    | WB  |    |
|-------+----+----+-----+-----+--------+-----+----|
| 指令3 |    |    | IF  | ID  | ALU    | Mem | WB |
|-------+----+----+-----+-----+--------+-----+----|
|       |              1400ps                     |
|-------+-----------------------------------------|

我们能够看到, 当我们执行的指令足够多的时候, 其效率能够提升几倍(这个背
倍数刚好是分开的步骤的数目). 值得注意的是, ID为读寄存器, WB为写寄存器,
其需要的时间均为 100ps (假设). 那么不适用流水线的情况下, 单条指令的执
行时间为 800ps. 而流水线中, 指令的执行时间为 1000ps 为了让读写操作和其
他项目对齐, 各设置了一个 100ps 的延迟.

*** 设计一个流水线

此时我们可见 risc-v 的优点: 

1. 指令长度等宽, 不像 x86 那个样子
2. 指令格式较为简单
3. 内存操作只有 load save 指令. x86 大部分指令可以进行内存的访问, 那么
   相当于 risc-v 的运算阶段, 内存访问阶段被扩展为了 
   1. 地址计算阶段;
   2. 内存访问阶段; 
   3. 运算阶段;
   这使得流水线长度增加. 

*** 流水线之中的冒险 (hazard)
**** 结构冒险

ALU 不能同时进行两对 A, B 的运算, 这大概就是结构冒险. 

**** 数据冒险 (data hazard)

我们有下面这个指令: 

    add x1, x2, x3
    sub x4, x1, x5

后一条指令的执行依赖于前面一条指令的结果. 没有算出 x1 就不能算后面那
条了. 只有当 ALU 运算结束了之后, WB之后, sub 的ID阶段才能取出 x1.

#+CAPTION: 理想的流水线
|-----+----+----+-----+-----+-----+----+---|
| add | If | Id | ALU | Mem | WB  |    |   |
|-----+----+----+-----+-----+-----+----+---|
| sub |    | IF | ID  | ALU | Mem | WB |   |
|-----+----+----+-----+-----+-----+----+---|
       
所以正确的样子应该是

#+CAPTION: 未改善的流水线
|-----+----+----+-----+-----+----+----+-----+-----+----+---|
| add | If | Id | ALU | Mem | WB |    |     |     |    |   |
|-----+----+----+-----+-----+----+----+-----+-----+----+---|
| sub |    |    |     |     | IF | ID | ALU | Mem | WB |   |
|-----+----+----+-----+-----+----+----+-----+-----+----+---|

这样就拖慢了流水线的执行效率. 面对这样的数据冒险, 一种简单的解决方法称
为 *前递* (forward), 简单来说, 就是在第一条指令的运算阶段结束之后, 直
接将 ALU 运算的结果传入 sub 指令的运算阶段. 

前递并不能解决所有问题, 比如说我们将add 指令替换为 load 指令. 那么仅有
当 Mem 阶段结束之后, 才有可能进行sub 的操作. 此时就别无选择, 得将 sub
指令往后移动一个阶段, 再使用前递. 参见下图.

#+CAPTION: 使用了前递之后, 流程就和正常一样. 
|-----+----+----+-----+-----+-----+----|
| add | IF | ID | ALU | Mem | WB  |    |
| sub |    | IF | ID  | ALU | Mem | WB |
|-----+----+----+-----+-----+-----+----|

比如说我们将 add 换为 load. 情况就不一样了. 

   ld x1, 0(x2)
   sub x2, x2, x1

#+CAPTION: 将 add 换为了 ld, 理想上的流水线
|-----+----+----+-----+-------+-----+----|
| ld  | IF | ID | ALU | ~Mem~ | WB  |    |
| sub |    | IF | ID  | ~ALU~ | Mem | WB |
|-----+----+----+-----+-------+-----+----|

只有当 Mem 结束之后, 才能处理数据, 才可能进行 sub 的 ALU 阶段. 那么,此
时, 如果说不能调换指令顺序来消除冒险的话, 无可奈何只能将 sub 延迟一个
单位. 这个操作称为 *流水线停顿* (pipeline stall), 也称 *bubble*, 可以
理解为, ld 指令和 sub 指令之间塞入了一个 bubble 指令, 此指令是一个空指
令, 即什么都不作的指令.

#+CAPTION: 流水线停顿, BUBBLE, Mem 阶段结束之后, 立即将数据传到 ALU 中
|--------+-----+-----+-----+-----+-----+-----+----|
| ld     | IF  | ID  | ALU | Mem | WB  |     |    |
| BUBBLE |     | bub | bub | bub | bub | bub |    |
| sub    |     |     | IF  | ID  | ALU | Mem | WB |
|--------+-----+-----+-----+-----+-----+-----+----|
  
书上 Example: 首先我们可以找出前递消除的冒险, 然后再找出前递无法消除的
冒险, 我们可以调换这些指令的顺序来解决冒险    
** 流水线数据通路和控制

流水线的通路过程是复杂的, 届时我们会知道. 

** TODO 数据冒险 (data hazard)
*** TODO fill in the blanks 

   ld x1, 0(x2)
   sub x2, x2, x1

此组合构成了数据冒险, 因为我们必须在 ld 的 Mem 阶段结束之后才能将数据
传输到 sub 阶段中的 ALU 阶段. 

#+CAPTION: 流水线停顿, BUBBLE, Mem 阶段结束之后, 立即将数据传到 ALU 中
|--------+-----+-----+-----+-----+-----+-----+----|
| ld     | IF  | ID  | ALU | Mem | WB  |     |    |
| BUBBLE |     | bub | bub | bub | bub | bub |    |
| sub    |     |     | IF  | ID  | ALU | Mem | WB |
|--------+-----+-----+-----+-----+-----+-----+----|



** DONE 控制冒险
   CLOSED: [2023-04-14 Fri 00:46]

   - State "DONE"       from "TODO"       [2023-04-14 Fri 00:46]

This section have two parts: 

1. The forward 
2. The prediction 

*** Forward 

Forward is to say that we treat the B instructions
simultaneously. That is to say, we

1. Calc PC + offset 
2. Decode the instructions 
3. Tell if jump

At the same stage: ID. You may guess that it has a harsh hardware
requirement.

*** prediction 
branch direction prediction is some *structures* to predict the branch
is taken or not, to mitigate the effect caused by branch
instructions. 

There are two kinds of branch direction prediction. They are: 

1. Static branch prediction 
2. Dynamic branch prediction

The first kind is achieve by software or something like "we always
predict that the branch is not taken". 

The second kind is achieved by some structures in the CPU. 

**** Static branch prediction

1. We say that the branch is always taken or is not taken. 
2. Heuristic depending on the instruction
3. Hint bits in the ISA. 

**** Dynamic branch prediction

1. We use bimodal predictors. 

We use one bit to write down the previous result. That is if the
branch now is taken, then we write 1 to the table. If the branch is
now taken, then we write 0 to the table. 

If the table is 1, then we predict that the branch is to be taken. 
If the table is 0, then we predict that the branch is not to be
taken. 

It looks very easy. But performs badly under certain circumstances. 

2. We use bimodal prediction with hyseresis. 

That is a two bit table. If the branch is taken, then the table is
added with 1. If not, the table is added with -1. 

If the first bit of the table is 1, we predict that it happens. 
If the first bit of the table is 0, we predict that it does not
happen. 



3. We use two-level adaptive branch prediction. 

That is we use a shift register to store the history. If the history
length is pretty long and it have been run for a while, then it can
predict the branch result. 

It works better when the loop of the branch is short. 

**** Hybrid or tournament branch prediction
*** TODO BTB
*** Some references
https://www.cs.umd.edu/~meesh/411/CA-online/chapter/dynamic-branch-prediction/index.html
https://www.cs.cmu.edu/afs/cs/academic/class/15740-s17/www/lectures/L19-BranchPrediction.pdf
https://people.engr.tamu.edu/djimenez/taco/utsa-www/cs5513-fall07/lecture4.html
** TODO Exceptions and interruptions